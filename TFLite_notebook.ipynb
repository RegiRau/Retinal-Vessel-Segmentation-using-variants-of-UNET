{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "patch_size = 512\n",
    "\n",
    "#loading model architectures\n",
    "from model import unetmodel, residualunet, attentionunet, residual_attentionunet\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from evaluation_metrics import IoU_coef,IoU_loss\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from patchify import patchify, unpatchify\n",
    "import skimage\n",
    "\n",
    "# CLAHE\n",
    "def clahe_equalized(imgs):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    imgs_equalized = clahe.apply(imgs)\n",
    "    return imgs_equalized\n",
    "\n",
    "IMG_HEIGHT = patch_size\n",
    "IMG_WIDTH = patch_size\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "\n",
    "model = attentionunet(input_shape) #/residualunet(input_shape)/unetmodel(input_shape)/attention_residualunet(input_shape)\n",
    "model.compile(optimizer = Adam(learning_rate = 1e-3), loss= IoU_loss, metrics= ['accuracy', IoU_coef])\n",
    "model.load_weights('M:\\Regine Rausch/05 Data/05 Segmentation Network\\Retinal-Vessel-Segmentation-using-variants-of-UNET'\n",
    "                   '\\Trained models/retina_attentionUnet_150epochs.hdf5') #loading weights\n",
    "\n",
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"attention_Unet_lite.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "quant_tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"attention_Unet_quant_lite.tflite\", \"wb\").write(quant_tflite_model)\n",
    "\n",
    "#load test image\n",
    "path1 = 'M:\\Regine Rausch/05 Data/05 Segmentation Network/healthy'              #test images directory path\n",
    "path2 = 'M:\\Regine Rausch/05 Data/05 Segmentation Network/healthy_manualsegm'   #label images directory path\n",
    "\n",
    "testimg = []\n",
    "ground_truth = []\n",
    "prediction = []\n",
    "global_IoU = []\n",
    "global_accuracy = []\n",
    "\n",
    "testimages = sorted(os.listdir(path1))\n",
    "testmasks =  sorted(os.listdir(path2))\n",
    "\n",
    "idx = 0\n",
    "image_name = testimages[0]\n",
    "#for idx, image_name in enumerate(testimages):\n",
    "if image_name.endswith(\".jpg\"):\n",
    "    predicted_patches = []\n",
    "    test_img = skimage.io.imread(path1 + \"/\" + image_name)\n",
    "\n",
    "    test = test_img[:, :, 1]  # selecting green channel\n",
    "    test = clahe_equalized(test)  # applying CLAHE\n",
    "    SIZE_X = (test_img.shape[1] // patch_size) * patch_size  # getting size multiple of patch size\n",
    "    SIZE_Y = (test_img.shape[0] // patch_size) * patch_size  # getting size multiple of patch size\n",
    "    test = cv2.resize(test, (SIZE_X, SIZE_Y))\n",
    "    testimg.append(test)\n",
    "    test = np.array(test)\n",
    "\n",
    "    patches = patchify(test, (patch_size, patch_size), step=patch_size)  # create patches(patch_sizexpatch_sizex1)\n",
    "\n",
    "    for i in range(patches.shape[0]):\n",
    "        for j in range(patches.shape[1]):\n",
    "            single_patch = patches[i, j, :, :]\n",
    "            single_patch_norm = (single_patch.astype('float32')) / 255.\n",
    "            single_patch_norm = np.expand_dims(np.array(single_patch_norm), axis=-1)\n",
    "            single_patch_input = np.expand_dims(single_patch_norm, 0)\n",
    "\n",
    "            # TF model\n",
    "            single_patch_prediction = (model.predict(single_patch_input)[0, :, :, 0] > 0.5).astype(\n",
    "                np.uint8)  # predict on single patch\n",
    "\n",
    "            # Load the TFLite model and allocate tensors.\n",
    "            #https://www.tensorflow.org/lite/guide/inference#load_and_run_a_model_in_python\n",
    "            interpreter = tf.lite.Interpreter(model_path=\"attention_Unet_lite.tflite\")\n",
    "            interpreter.allocate_tensors()\n",
    "            # Get input and output tensors.\n",
    "            input_details = interpreter.get_input_details()\n",
    "            output_details = interpreter.get_output_details()\n",
    "            # Test the model on random input data.\n",
    "            input_shape = input_details[0]['shape']\n",
    "            #input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "            input_data = single_patch_input\n",
    "            interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "            interpreter.invoke()\n",
    "            # The function `get_tensor()` returns a copy of the tensor data.\n",
    "            # Use `tensor()` in order to get a pointer to the tensor.\n",
    "            output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "            output = (output_data[0, :, :, 0] > 0.5).astype(np.uint8)\n",
    "\n",
    "            predicted_patches.append(single_patch_prediction)\n",
    "    predicted_patches = np.array(predicted_patches)\n",
    "    predicted_patches_reshaped = np.reshape(predicted_patches,\n",
    "                                            (patches.shape[0], patches.shape[1], patch_size, patch_size))\n",
    "    reconstructed_image = unpatchify(predicted_patches_reshaped, test.shape)  # join patches to form whole img\n",
    "    prediction.append(reconstructed_image)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}